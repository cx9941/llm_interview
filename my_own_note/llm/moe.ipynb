{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba23bda2",
   "metadata": {},
   "source": [
    "# Mixture of Experts (MoE) 简介\n",
    "\n",
    "## 1. 基本思想\n",
    "\n",
    "- **普通 FFN**：在 Transformer 中，前馈层是一个固定的全连接网络：\n",
    "  $$\n",
    "  x \\to W_1 \\to \\sigma \\to W_2 \\to y\n",
    "  $$\n",
    "\n",
    "- **MoE**：引入多个专家（experts），每个专家都是一个 FFN。输入 token 不再经过所有专家，而是由路由器 (router) 选择其中的少数几个（如 Top-1 或 Top-2）来处理，再将结果加权合并。\n",
    "\n",
    "- **优势**：在不增加推理 FLOPs 的前提下，大幅增加模型参数量，实现稀疏激活。\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 数学公式\n",
    "\n",
    "### (1) 路由概率\n",
    "对输入向量 $x \\in \\mathbb{R}^d$，路由器计算专家得分：\n",
    "$$\n",
    "g(x) = \\text{softmax}(W_r x) \\in \\mathbb{R}^E\n",
    "$$\n",
    "其中 $E$ 为专家数，$W_r \\in \\mathbb{R}^{E \\times d}$，$g_i(x)$ 表示专家 $i$ 被选中的概率。\n",
    "\n",
    "### (2) Top-k 路由\n",
    "选择前 $k$ 个专家：\n",
    "$$\n",
    "\\text{TopK}(g(x)) = \\{(i_1, p_1), (i_2, p_2), \\dots, (i_k, p_k)\\}\n",
    "$$\n",
    "其中 $i_j$ 是专家索引，$p_j$ 是归一化后的概率。\n",
    "\n",
    "### (3) 专家计算\n",
    "每个专家是一个前馈网络：\n",
    "$$\n",
    "f_i(x) = W_{2,i} \\cdot \\sigma(W_{1,i} x + b_{1,i}) + b_{2,i}\n",
    "$$\n",
    "\n",
    "### (4) MoE 输出\n",
    "MoE 的最终输出是加权和：\n",
    "$$\n",
    "y = \\sum_{j=1}^k p_j \\cdot f_{i_j}(x)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 正则化损失\n",
    "\n",
    "### (1) 负载均衡损失\n",
    "防止路由器过度集中在少数专家：\n",
    "$$\n",
    "L_{\\text{aux}} = E \\cdot \\sum_{i=1}^E \\big( \\text{importance}_i \\cdot \\text{load}_i \\big)\n",
    "$$\n",
    "其中  \n",
    "- $\\text{importance}_i = \\sum_x g_i(x)$  \n",
    "- $\\text{load}_i = \\sum_x \\mathbf{1}[\\arg\\max g(x) = i]$\n",
    "\n",
    "### (2) Router z-loss\n",
    "约束 router logits 的数值范围：\n",
    "$$\n",
    "L_z = \\mathbb{E}\\Bigg[\\Big(\\log \\sum_{i=1}^E \\exp((W_r x)_i)\\Big)^2\\Bigg]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4. 直观理解\n",
    "\n",
    "- 普通 FFN：所有 token 走同一个专家。  \n",
    "- MoE：每个 token 根据路由结果走不同专家，像医院分诊。  \n",
    "- 好处：参数量可以无限增大，但单 token 的计算开销保持可控。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd050b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Expert：普通 FFN\n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, d_model, d_hidden):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_hidden)\n",
    "        self.fc2 = nn.Linear(d_hidden, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.gelu(self.fc1(x)))\n",
    "\n",
    "# Router：Top-2 路由\n",
    "class Router(nn.Module):\n",
    "    def __init__(self, d_model, n_experts):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(d_model, n_experts, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.gate(x)                      # [B,T,E]\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        topk_prob, topk_idx = probs.topk(2, dim=-1)\n",
    "        topk_prob = topk_prob / topk_prob.sum(-1, keepdim=True)\n",
    "        return topk_idx, topk_prob\n",
    "\n",
    "# MoE 层：调度 + 聚合\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, d_model, d_hidden, n_experts):\n",
    "        super().__init__()\n",
    "        self.experts = nn.ModuleList([Expert(d_model, d_hidden) for _ in range(n_experts)])\n",
    "        self.router = Router(d_model, n_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B,T,D]\n",
    "        B, T, D = x.shape\n",
    "        idx, prob = self.router(x)   # [B,T,2], [B,T,2]\n",
    "\n",
    "        y = torch.zeros_like(x)\n",
    "        for k in range(2):           # top-2 experts\n",
    "            e_idx = idx[..., k]      # [B,T]\n",
    "            p = prob[..., k][..., None]  # [B,T,1]\n",
    "            for e in range(len(self.experts)):\n",
    "                mask = (e_idx == e)\n",
    "                if mask.any():\n",
    "                    y[mask] += p[mask] * self.experts[e](x[mask])\n",
    "        return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
