{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e09daf8d",
   "metadata": {},
   "source": [
    "### 基础代码\n",
    "手撕 KL散度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6b0f5",
   "metadata": {},
   "source": [
    "给出公式 $KL(P, Q)=\\sum P(i) \\log \\frac{P(i)}{Q(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5535b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def KL_divergence(x, y, eps=1e-12):\n",
    "    x = x / x.sum(dim=-1)\n",
    "    y = y / y.sum(dim=-1)\n",
    "    \n",
    "    x = x + eps\n",
    "    y = y + eps\n",
    "    sum = x * torch.log(x / y)\n",
    "    return torch.sum(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece9b555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0201)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0.4, 0.6])\n",
    "y = torch.tensor([0.5, 0.5])\n",
    "KL_divergence(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9efd3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0.5, 0.5])\n",
    "y = torch.tensor([0.5, 0.5])\n",
    "KL_divergence(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bd5a07",
   "metadata": {},
   "source": [
    "手撕交叉熵损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396f02f",
   "metadata": {},
   "source": [
    "给出公式 $H(P, Q) = \\sum Q(i)\\log P(i) = H(P) + KL(P, Q)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75e1a2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6094)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy(x, y):\n",
    "    sum = torch.log(x) * y\n",
    "    return -torch.sum(sum)\n",
    "\n",
    "x = torch.tensor([0.1, 0.2, 0.6, 0.1])\n",
    "y = torch.tensor([0, 1, 0, 0])\n",
    "loss = cross_entropy(x, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c488fd6",
   "metadata": {},
   "source": [
    "手撕优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655337f1",
   "metadata": {},
   "source": [
    "手撕SGD优化器\n",
    "\n",
    "$\\theta_i = \\theta_i - g_i$\n",
    "\n",
    "带动量的优化器\n",
    "\n",
    "$\\hat{g}_i = \\lambda g_{i-1} + g_i  $\n",
    "\n",
    "$\\theta_i = \\theta_i - lr * \\hat{g}_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SGDOptimizer:\n",
    "    def __init__(self, params, lr=1e-3):\n",
    "        \"\"\"\n",
    "        params: 可迭代的模型参数\n",
    "        lr: 学习率 α\n",
    "        \"\"\"\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "            # 参数更新 θ ← θ - α * grad\n",
    "            p.data -= self.lr * p.grad.data\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.detach_()\n",
    "                p.grad.zero_()\n",
    "\n",
    "class SGDMomentumOptimizer:\n",
    "    def __init__(self, params, lr=1e-3, momentum=0.9):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = [torch.zeros_like(p) for p in self.params]  # 初始化动量\n",
    "\n",
    "    def step(self):\n",
    "        for i, p in enumerate(self.params):\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "            # v_t = μ v_{t-1} + grad\n",
    "            self.v[i] = self.momentum * self.v[i] + p.grad.data\n",
    "            # θ ← θ - α * v_t\n",
    "            p.data -= self.lr * self.v[i]\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.detach_()\n",
    "                p.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4057601",
   "metadata": {},
   "source": [
    "手撕Adam优化器\n",
    "\n",
    "公式：\n",
    "参数 $\\beta_1$, $\\beta_2$, lr, eps\n",
    "\n",
    "额外的，有一步权重衰减\n",
    "$g_i = g_i + \\lambda \\theta_i$\n",
    "\n",
    "\n",
    "$m_i = (1 - \\beta_1) * g_i + m_{i+1}$\n",
    "\n",
    "$v_i = (1 - \\beta_2) * g_i^2 + v_{i+1}$\n",
    "\n",
    "\n",
    "$\\theta_i = \\theta_{i-1} - lr * \\frac{m_i / (1 - \\beta_1^i)}{\\sqrt(v_i / (1 - \\beta_2^i)) + eps}$\n",
    "\n",
    "\n",
    "Adamw的区别就在于权重衰减是在外面\n",
    "$\\theta_i = \\theta_i - lr * \\theta_i * w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f7e1ab4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3576334902.py, line 28)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[31m    \u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class Adam:\n",
    "    def __init__(self, params, lr=5e-5, betas=(0.9, 0.99), eps=1e-10):\n",
    "        self.beta_1, self.beta_2 = betas\n",
    "        self.alpha = 1\n",
    "        self.lr = lr\n",
    "\n",
    "        self.m = [torch.zeros(para.shape) for para in params]\n",
    "        self.v = [torch.zeros(para.shape) for para in params]\n",
    "\n",
    "        self.params = params\n",
    "        self.t = 1\n",
    "    \n",
    "    def step(self):\n",
    "        for i, para in enumerate(self.params):\n",
    "            m = (1 - self.beta1) * para.grad + self.m[i][-1]\n",
    "            v = (1 - self.beta2) * (para.grad ** 2) + self.v[i][-1]\n",
    "            self.m.append(m)\n",
    "            self.v.append(v)\n",
    "            m_hat = m / (1 - self.beta_1 ** self.t)\n",
    "            v_hat = v / (1 - self.beta_2 ** self.t)\n",
    "            para.data -= - m_hat / ( v_hat ** 0.5 + self.eps ) * self.lr\n",
    "\n",
    "        self.t += 1\n",
    "\n",
    "    def zero_step(self):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c510b385",
   "metadata": {},
   "source": [
    "手撕AdamW优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871ebb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecd49b63",
   "metadata": {},
   "source": [
    "手撕AUC\n",
    "\n",
    "$AUC = \\frac{R_{pos} - \\frac{n_{pos}(n_{pos} + 1)}{2}}{n_{pos} \\cdot n_{neg}}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
